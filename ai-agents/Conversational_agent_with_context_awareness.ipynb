{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b0749c",
   "metadata": {},
   "source": [
    "# Conversational Agent with Context Awareness\n",
    "\n",
    "This notebook explores an experiment in building a conversational agent that **remembers context across turns**. Unlike stateless chatbots that forget past interactions, this agent keeps track of prior messages within each session, making conversations more natural and coherent.  \n",
    "The design uses:\n",
    "- **Prompt templates** to structure the interaction.  \n",
    "- **Message history management** to retain and replay conversation context.  \n",
    "- **A lightweight session-based store** to isolate multiple conversations.  \n",
    "\n",
    "The focus here is not on polished production code, but on experimenting with the essential building blocks of agents that can \"hold a thought\" over time.\n",
    "\n",
    "### Tech-Stack\n",
    "\n",
    "- **LangChain**: for chaining prompts and managing conversational flow.  \n",
    "- **OpenAI GPT (gpt-4o-mini)**: as the underlying language model for response generation.  \n",
    "- **ChatMessageHistory**: to capture and replay conversation history.  \n",
    "- **RunnableWithMessageHistory**: for injecting session-based memory into the prompt.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q langchain langchain_experimental openai python-dotenv langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85574c40",
   "metadata": {},
   "source": [
    "#### Importing reqquired libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204833d",
   "metadata": {},
   "source": [
    "#### Loading environment variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c3e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11651596",
   "metadata": {},
   "source": [
    "#### In-memory store for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735be845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5798f3b",
   "metadata": {},
   "source": [
    "#### Build the prompt-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0cddc",
   "metadata": {},
   "source": [
    "#### prompt-model chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f171448",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58b604",
   "metadata": {},
   "source": [
    "#### Wrap the chain with message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00198b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6412d",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa563774",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response1.content)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous message?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a37eda",
   "metadata": {},
   "source": [
    "## Summary\n",
    "I think I can improve this concept by:\n",
    "\n",
    "- ***Persistent Memory / Storage***  \n",
    "  [e.g., Replace in-memory storage with Redis, Postgres, or MongoDB for durable, scalable sessions.]  \n",
    "\n",
    "- ***Context Management***  \n",
    "  [e.g., Introduce summarization memory or vector-backed memory (FAISS, Chroma, Weaviate) to handle long conversations efficiently.]  \n",
    "\n",
    "- ***Knowledge Augmentation (RAG)***  \n",
    "  [e.g., Integrate retrieval pipelines with pgVector, Pinecone, or Chroma to ground answers in external documents and databases.]  \n",
    "\n",
    "- ***Tool Integration***  \n",
    "  [e.g., Extend the agent with LangChain Agents or LangGraph to perform API calls, DB queries, or calculations.]  \n",
    "\n",
    "- ***Personalization***  \n",
    "  [e.g., Track user preferences or profiles to deliver adaptive, customized interactions.]  \n",
    "\n",
    "- ***Monitoring & Reliability***  \n",
    "  [e.g., Add observability via LangSmith, Prometheus, or OpenTelemetry; implement rate-limit handling and usage tracking.]  \n",
    "\n",
    "- ***Error Handling & Recovery***  \n",
    "  [e.g., Add clarification prompts, fallback responses, and repair strategies for ambiguous or failed outputs.]  \n",
    "\n",
    "This can transform this simple context-aware agent into a **production-ready, scalable, and enterprise-relevant conversational system**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
